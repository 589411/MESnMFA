"""
CCL æ¨¹è„‚é…æ–¹å„ªåŒ–å™¨ (åå‘è¨­è¨ˆ)
=============================
çµ¦å®šç›®æ¨™è¦æ ¼ï¼Œæœå°‹æœ€ä½³é…æ–¹
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple, Callable
from dataclasses import dataclass, field
import random

from predictor import CCLPredictor, ModelConfig


@dataclass
class TargetSpec:
    """ç›®æ¨™è¦æ ¼"""
    name: str
    target_type: str  # 'min', 'max', 'range'
    value: float = None
    min_value: float = None
    max_value: float = None
    weight: float = 1.0  # æ¬Šé‡ï¼Œç”¨æ–¼å¤šç›®æ¨™å„ªåŒ–
    
    def is_satisfied(self, actual: float) -> bool:
        """æª¢æŸ¥æ˜¯å¦æ»¿è¶³è¦æ ¼"""
        if self.target_type == 'min':
            return actual >= self.value
        elif self.target_type == 'max':
            return actual <= self.value
        elif self.target_type == 'range':
            return self.min_value <= actual <= self.max_value
        return False
    
    def get_penalty(self, actual: float) -> float:
        """è¨ˆç®—é•åè¦æ ¼çš„æ‡²ç½°å€¼"""
        if self.target_type == 'min':
            if actual >= self.value:
                return 0
            return (self.value - actual) * self.weight
        elif self.target_type == 'max':
            if actual <= self.value:
                return 0
            return (actual - self.value) * self.weight
        elif self.target_type == 'range':
            if self.min_value <= actual <= self.max_value:
                return 0
            if actual < self.min_value:
                return (self.min_value - actual) * self.weight
            return (actual - self.max_value) * self.weight
        return 0


@dataclass
class FormulationBounds:
    """é…æ–¹åƒæ•¸ç¯„åœ"""
    Hardener_Eq_Ratio: Tuple[float, float] = (0.75, 1.15)
    Filler_Vol_Pct: Tuple[float, float] = (15, 55)
    FR_Wt_Pct: Tuple[float, float] = (3, 8)
    Toughener_Wt_Pct: Tuple[float, float] = (0, 8)
    Wash_Cycles: Tuple[int, int] = (2, 5)
    Residual_Cl_ppm: Tuple[float, float] = (5, 45)
    
    def get_bounds(self) -> Dict[str, Tuple]:
        return {
            'Hardener_Eq_Ratio': self.Hardener_Eq_Ratio,
            'Filler_Vol_Pct': self.Filler_Vol_Pct,
            'FR_Wt_Pct': self.FR_Wt_Pct,
            'Toughener_Wt_Pct': self.Toughener_Wt_Pct,
            'Wash_Cycles': self.Wash_Cycles,
            'Residual_Cl_ppm': self.Residual_Cl_ppm
        }


class CCLOptimizer:
    """CCL é…æ–¹å„ªåŒ–å™¨"""
    
    def __init__(self, predictor: CCLPredictor, bounds: Optional[FormulationBounds] = None):
        self.predictor = predictor
        self.bounds = bounds or FormulationBounds()
        self.target_specs: List[TargetSpec] = []
        
    def set_targets(self, specs: Dict[str, Dict]):
        """
        è¨­å®šç›®æ¨™è¦æ ¼
        
        Parameters
        ----------
        specs : Dict[str, Dict]
            ä¾‹å¦‚:
            {
                'Dk_10GHz': {'type': 'max', 'value': 3.5, 'weight': 2.0},
                'Df_10GHz': {'type': 'max', 'value': 0.010},
                'Peel_Strength_N_mm': {'type': 'min', 'value': 0.7},
                'Tg_C': {'type': 'min', 'value': 160},
                'CTE_ppm': {'type': 'max', 'value': 35}
            }
        """
        self.target_specs = []
        for name, spec in specs.items():
            target_type = spec.get('type', 'max')
            value = spec.get('value')
            min_val = spec.get('min')
            max_val = spec.get('max')
            weight = spec.get('weight', 1.0)
            
            self.target_specs.append(TargetSpec(
                name=name,
                target_type=target_type,
                value=value,
                min_value=min_val,
                max_value=max_val,
                weight=weight
            ))
        
        print(f"âœ… å·²è¨­å®š {len(self.target_specs)} å€‹ç›®æ¨™è¦æ ¼")
    
    def _random_formulation(self) -> Dict[str, float]:
        """ç”Ÿæˆéš¨æ©Ÿé…æ–¹"""
        bounds = self.bounds.get_bounds()
        formulation = {}
        for param, (low, high) in bounds.items():
            if param == 'Wash_Cycles':
                formulation[param] = random.randint(int(low), int(high))
            else:
                formulation[param] = random.uniform(low, high)
        return formulation
    
    def _evaluate_formulation(self, formulation: Dict[str, float]) -> Tuple[Dict, float, bool]:
        """
        è©•ä¼°é…æ–¹
        
        Returns
        -------
        predictions : Dict
            é æ¸¬çš„ç‰©ç†æ€§è³ª
        total_penalty : float
            ç¸½æ‡²ç½°å€¼ (è¶Šä½è¶Šå¥½)
        all_satisfied : bool
            æ˜¯å¦æ»¿è¶³æ‰€æœ‰è¦æ ¼
        """
        predictions = self.predictor.predict(formulation)
        
        total_penalty = 0
        all_satisfied = True
        
        for spec in self.target_specs:
            actual = predictions.get(spec.name, 0)
            penalty = spec.get_penalty(actual)
            total_penalty += penalty
            
            if not spec.is_satisfied(actual):
                all_satisfied = False
        
        return predictions, total_penalty, all_satisfied
    
    def grid_search(self, n_samples: int = 10000, n_results: int = 10) -> pd.DataFrame:
        """
        ç¶²æ ¼æœå°‹ (éš¨æ©Ÿæ¡æ¨£)
        
        Parameters
        ----------
        n_samples : int
            æ¡æ¨£æ•¸é‡
        n_results : int
            è¿”å›å‰ N å€‹æœ€ä½³çµæœ
        
        Returns
        -------
        pd.DataFrame
            æœ€ä½³é…æ–¹åˆ—è¡¨
        """
        print(f"\nğŸ” é–‹å§‹ç¶²æ ¼æœå°‹ ({n_samples} å€‹é…æ–¹)...")
        
        results = []
        satisfied_count = 0
        
        for i in range(n_samples):
            formulation = self._random_formulation()
            predictions, penalty, satisfied = self._evaluate_formulation(formulation)
            
            result = {**formulation, **predictions, 'penalty': penalty, 'satisfied': satisfied}
            results.append(result)
            
            if satisfied:
                satisfied_count += 1
            
            if (i + 1) % 2000 == 0:
                print(f"  é€²åº¦: {i+1}/{n_samples}, ç¬¦åˆè¦æ ¼: {satisfied_count}")
        
        # è½‰æ›ç‚º DataFrame ä¸¦æ’åº
        df_results = pd.DataFrame(results)
        df_results = df_results.sort_values('penalty').reset_index(drop=True)
        
        print(f"\nâœ… æœå°‹å®Œæˆ!")
        print(f"   ç¬¦åˆæ‰€æœ‰è¦æ ¼: {satisfied_count}/{n_samples} ({satisfied_count/n_samples*100:.1f}%)")
        
        return df_results.head(n_results)
    
    def genetic_algorithm(
        self, 
        population_size: int = 100,
        generations: int = 50,
        mutation_rate: float = 0.1,
        n_results: int = 10
    ) -> pd.DataFrame:
        """
        éºå‚³æ¼”ç®—æ³•å„ªåŒ–
        
        Parameters
        ----------
        population_size : int
            æ—ç¾¤å¤§å°
        generations : int
            æ¼”åŒ–ä»£æ•¸
        mutation_rate : float
            çªè®Šç‡
        n_results : int
            è¿”å›å‰ N å€‹æœ€ä½³çµæœ
        
        Returns
        -------
        pd.DataFrame
            æœ€ä½³é…æ–¹åˆ—è¡¨
        """
        print(f"\nğŸ§¬ é–‹å§‹éºå‚³æ¼”ç®—æ³•å„ªåŒ–...")
        print(f"   æ—ç¾¤å¤§å°: {population_size}, ä»£æ•¸: {generations}")
        
        bounds = self.bounds.get_bounds()
        param_names = list(bounds.keys())
        
        # åˆå§‹åŒ–æ—ç¾¤
        population = [self._random_formulation() for _ in range(population_size)]
        
        best_penalty = float('inf')
        best_formulation = None
        
        for gen in range(generations):
            # è©•ä¼°é©æ‡‰åº¦
            fitness_scores = []
            for individual in population:
                _, penalty, _ = self._evaluate_formulation(individual)
                fitness_scores.append(penalty)
            
            # è¨˜éŒ„æœ€ä½³
            min_penalty_idx = np.argmin(fitness_scores)
            if fitness_scores[min_penalty_idx] < best_penalty:
                best_penalty = fitness_scores[min_penalty_idx]
                best_formulation = population[min_penalty_idx].copy()
            
            # é¸æ“‡ (è¼ªç›¤è³­)
            # å°‡æ‡²ç½°è½‰æ›ç‚ºé©æ‡‰åº¦ (è¶Šä½è¶Šå¥½ -> è¶Šé«˜è¶Šå¥½)
            max_penalty = max(fitness_scores) + 1
            fitness = [max_penalty - p for p in fitness_scores]
            total_fitness = sum(fitness)
            probabilities = [f / total_fitness for f in fitness]
            
            # é¸æ“‡çˆ¶ä»£
            selected_indices = np.random.choice(
                len(population), 
                size=population_size, 
                p=probabilities, 
                replace=True
            )
            selected = [population[i] for i in selected_indices]
            
            # äº¤å‰
            new_population = []
            for i in range(0, population_size, 2):
                parent1 = selected[i]
                parent2 = selected[min(i + 1, population_size - 1)]
                
                # å–®é»äº¤å‰
                crossover_point = random.randint(1, len(param_names) - 1)
                child1 = {}
                child2 = {}
                for j, param in enumerate(param_names):
                    if j < crossover_point:
                        child1[param] = parent1[param]
                        child2[param] = parent2[param]
                    else:
                        child1[param] = parent2[param]
                        child2[param] = parent1[param]
                
                new_population.extend([child1, child2])
            
            # çªè®Š
            for individual in new_population:
                if random.random() < mutation_rate:
                    # éš¨æ©Ÿé¸æ“‡ä¸€å€‹åƒæ•¸é€²è¡Œçªè®Š
                    param = random.choice(param_names)
                    low, high = bounds[param]
                    if param == 'Wash_Cycles':
                        individual[param] = random.randint(int(low), int(high))
                    else:
                        individual[param] = random.uniform(low, high)
            
            population = new_population[:population_size]
            
            # ç²¾è‹±ä¿ç•™
            population[0] = best_formulation.copy()
            
            if (gen + 1) % 10 == 0:
                print(f"  ä»£æ•¸ {gen+1}/{generations}, æœ€ä½³æ‡²ç½°å€¼: {best_penalty:.4f}")
        
        # æœ€çµ‚è©•ä¼°
        results = []
        for individual in population:
            predictions, penalty, satisfied = self._evaluate_formulation(individual)
            result = {**individual, **predictions, 'penalty': penalty, 'satisfied': satisfied}
            results.append(result)
        
        df_results = pd.DataFrame(results)
        df_results = df_results.sort_values('penalty').reset_index(drop=True)
        df_results = df_results.drop_duplicates(subset=list(bounds.keys())).head(n_results)
        
        print(f"\nâœ… éºå‚³æ¼”ç®—æ³•å®Œæˆ!")
        
        return df_results
    
    def search(
        self, 
        method: str = 'grid',
        n_results: int = 10,
        **kwargs
    ) -> pd.DataFrame:
        """
        æœå°‹æœ€ä½³é…æ–¹
        
        Parameters
        ----------
        method : str
            'grid' (ç¶²æ ¼æœå°‹) æˆ– 'genetic' (éºå‚³æ¼”ç®—æ³•)
        n_results : int
            è¿”å›çµæœæ•¸é‡
        **kwargs
            å‚³éçµ¦å…·é«”æ–¹æ³•çš„åƒæ•¸
        
        Returns
        -------
        pd.DataFrame
            æœ€ä½³é…æ–¹åˆ—è¡¨
        """
        if method == 'grid':
            return self.grid_search(n_results=n_results, **kwargs)
        elif method == 'genetic':
            return self.genetic_algorithm(n_results=n_results, **kwargs)
        else:
            raise ValueError(f"Unknown method: {method}")


def format_results(df: pd.DataFrame, target_specs: List[TargetSpec]) -> str:
    """æ ¼å¼åŒ–è¼¸å‡ºçµæœ"""
    output = []
    output.append("\n" + "=" * 80)
    output.append("ğŸ† æœ€ä½³é…æ–¹æœå°‹çµæœ")
    output.append("=" * 80)
    
    for i, row in df.iterrows():
        output.append(f"\nğŸ“‹ é…æ–¹ #{i+1} {'âœ… ç¬¦åˆè¦æ ¼' if row['satisfied'] else 'âŒ æœªå®Œå…¨ç¬¦åˆ'}")
        output.append("-" * 40)
        
        # é…æ–¹åƒæ•¸
        output.append("ã€é…æ–¹åƒæ•¸ã€‘")
        output.append(f"  ç¡¬åŒ–åŠ‘ç•¶é‡æ¯”:    {row['Hardener_Eq_Ratio']:.3f}")
        output.append(f"  å¡«æ–™é«”ç©%:       {row['Filler_Vol_Pct']:.1f} vol%")
        output.append(f"  é˜»ç‡ƒåŠ‘é‡é‡%:     {row['FR_Wt_Pct']:.2f} wt%")
        output.append(f"  å¢éŸŒåŠ‘é‡é‡%:     {row['Toughener_Wt_Pct']:.2f} wt%")
        output.append(f"  æ°´æ´—æ¬¡æ•¸:        {int(row['Wash_Cycles'])} æ¬¡")
        output.append(f"  æ®˜ç•™æ°¯é›¢å­:      {row['Residual_Cl_ppm']:.1f} ppm")
        
        # é æ¸¬æ€§è³ª
        output.append("\nã€é æ¸¬ç‰©ç†æ€§è³ªã€‘")
        for spec in target_specs:
            actual = row[spec.name]
            satisfied = spec.is_satisfied(actual)
            status = "âœ…" if satisfied else "âŒ"
            
            if spec.target_type == 'max':
                target_str = f"â‰¤ {spec.value}"
            elif spec.target_type == 'min':
                target_str = f"â‰¥ {spec.value}"
            else:
                target_str = f"{spec.min_value} ~ {spec.max_value}"
            
            output.append(f"  {spec.name:25s}: {actual:8.4f} (ç›®æ¨™: {target_str}) {status}")
        
        output.append(f"\n  ç¸½æ‡²ç½°å€¼: {row['penalty']:.4f}")
    
    return "\n".join(output)


if __name__ == '__main__':
    print("CCL æ¨¹è„‚é…æ–¹å„ªåŒ–å™¨")
    print("=" * 50)
    
    # è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹
    predictor = CCLPredictor()
    predictor.load_data('../data/ccl_resin_simulation.csv')
    predictor.train(model_type='random_forest')
    
    # å»ºç«‹å„ªåŒ–å™¨
    optimizer = CCLOptimizer(predictor)
    
    # è¨­å®šç›®æ¨™è¦æ ¼ (5G é«˜é » CCL è¦æ ¼)
    target_specs = {
        'Dk_10GHz': {'type': 'max', 'value': 3.5, 'weight': 2.0},
        'Df_10GHz': {'type': 'max', 'value': 0.010, 'weight': 2.0},
        'Peel_Strength_N_mm': {'type': 'min', 'value': 0.7, 'weight': 1.5},
        'Tg_C': {'type': 'min', 'value': 160, 'weight': 1.0},
        'CTE_ppm': {'type': 'max', 'value': 35, 'weight': 1.0}
    }
    optimizer.set_targets(target_specs)
    
    # æ–¹æ³• 1: ç¶²æ ¼æœå°‹
    print("\n" + "=" * 50)
    print("æ–¹æ³• 1: ç¶²æ ¼æœå°‹")
    print("=" * 50)
    results_grid = optimizer.search(method='grid', n_samples=10000, n_results=5)
    print(format_results(results_grid, optimizer.target_specs))
    
    # æ–¹æ³• 2: éºå‚³æ¼”ç®—æ³•
    print("\n" + "=" * 50)
    print("æ–¹æ³• 2: éºå‚³æ¼”ç®—æ³•")
    print("=" * 50)
    results_ga = optimizer.search(method='genetic', population_size=100, generations=30, n_results=5)
    print(format_results(results_ga, optimizer.target_specs))
